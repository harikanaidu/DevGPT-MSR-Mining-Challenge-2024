{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGY1JqTVUS6E",
        "outputId": "96c92cc7-19d3-4c6e-e6e7-f7af44e808dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Related Follow-Ups: 1341\n",
            "Total New Queries: 35\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def bert_encode(text):\n",
        "    if not text:\n",
        "        return np.zeros((1, model.config.dim))\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    if not tokens:\n",
        "        return np.zeros((1, model.config.dim))\n",
        "    tokens = tokens[:510]\n",
        "    input_ids = torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "        return outputs[0].mean(dim=1).detach().numpy()\n",
        "\n",
        "\n",
        "def calculate_similarity(text1, text2):\n",
        "    vec1 = bert_encode(text1)\n",
        "    vec2 = bert_encode(text2)\n",
        "    return cosine_similarity(vec1, vec2)[0][0]\n",
        "\n",
        "file_paths = [\n",
        "    \"20230727_195927_pr_sharings.json\",\n",
        "    \"20230727_195941_issue_sharings.json\",\n",
        "]\n",
        "\n",
        "total_related_follow_ups = 0\n",
        "total_new_queries = 0\n",
        "\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)['Sources']\n",
        "        for source in data:\n",
        "            for chatgpt_sharing in source.get('ChatgptSharing', []):\n",
        "                conversations = chatgpt_sharing.get('Conversations', [])\n",
        "                if len(conversations) > 1:\n",
        "                    for i in range(len(conversations) - 1):\n",
        "                        current_interaction = conversations[i]\n",
        "                        next_interaction = conversations[i + 1]\n",
        "                        similarity = calculate_similarity(current_interaction['Answer'], next_interaction['Prompt'])\n",
        "                        if similarity >= 0.5:\n",
        "                            total_related_follow_ups += 1\n",
        "                        else:\n",
        "                            total_new_queries += 1\n",
        "\n",
        "print(f\"Total Related Follow-Ups: {total_related_follow_ups}\")\n",
        "print(f\"Total New Queries: {total_new_queries}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "MnlBbn4sV1m3"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}